{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaejunlee/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.loadtxt(os.getcwd()+'/test.wav.txt')\n",
    "test_data.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_size': (3, 3),\n",
       " 'conv_stride': (1, 1),\n",
       " 'input_shape': (100, 40, 1),\n",
       " 'n_feature_maps': 19,\n",
       " 'n_labels': 12,\n",
       " 'n_layers': 6,\n",
       " 'res_pool': (4, 3),\n",
       " 'use_dilation': False}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = dict(input_shape=(100,40,1,), conv_size=(3,3), conv_stride=(1,1), n_labels=12, n_layers=6, n_feature_maps=19, res_pool=(4, 3), use_dilation=False)\n",
    "# \tRES8_NARROW : {\n",
    "# \t\tinput_shape : [40, 100, 1],\n",
    "# \t\tn_labels : 12,\n",
    "# \t\tn_layers : 6,\n",
    "# \t\tn_feature_maps : 19,\n",
    "# \t\tres_pool : [3, 4],\n",
    "# \t\tuse_dilation : false,\n",
    "# \t\tconv_size : [3, 3],\n",
    "# \t\tconv_stride : [1, 1]\n",
    "# \t},\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv0': <keras.layers.convolutional.Conv2D at 0xb1c724090>}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conv0 = tf.layers.conv2d({\n",
    "#     filters: this.config['n_feature_maps'],\n",
    "#     kernelSize: this.config['conv_size'],\n",
    "#     strides: this.config['conv_stride'],\n",
    "#     padding: \"same\",\n",
    "#     useBias: false,\n",
    "#     kernelInitializer: tf.initializers.zeros(),\n",
    "#     biasInitializer: tf.initializers.zeros(),\n",
    "# })\n",
    "layers['conv0'] = Conv2D(\n",
    "    filters=config['n_feature_maps'],\n",
    "    kernel_size=config['conv_size'],\n",
    "    strides=config['conv_stride'],\n",
    "    padding='same',\n",
    "    use_bias=False,\n",
    "    activation='relu',\n",
    "    kernel_initializer=keras.initializers.zeros(),\n",
    "    bias_initializer=keras.initializers.zeros(),\n",
    "    name = 'conv0'\n",
    ")\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv0': <keras.layers.convolutional.Conv2D at 0xb1c724090>,\n",
       " 'pool': <keras.layers.pooling.AveragePooling2D at 0xb1c70cb10>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this.pool = tf.layers.averagePooling2d({\n",
    "#     poolSize: this.config['res_pool']\n",
    "# })\n",
    "layers['pool'] = AveragePooling2D(\n",
    "    pool_size=config['res_pool'], \n",
    "    strides=None,\n",
    "    padding='same',\n",
    "    data_format=None,\n",
    "    name = 'pool')\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv0': <keras.layers.convolutional.Conv2D at 0xb1c724090>,\n",
       " 'conv1': <keras.layers.convolutional.Conv2D at 0xb1c724a10>,\n",
       " 'conv2': <keras.layers.convolutional.Conv2D at 0xb1c724ad0>,\n",
       " 'conv3': <keras.layers.convolutional.Conv2D at 0xb1c724bd0>,\n",
       " 'conv4': <keras.layers.convolutional.Conv2D at 0xb1c724cd0>,\n",
       " 'conv5': <keras.layers.convolutional.Conv2D at 0xb1c724dd0>,\n",
       " 'conv6': <keras.layers.convolutional.Conv2D at 0xb1c724ed0>,\n",
       " 'pool': <keras.layers.pooling.AveragePooling2D at 0xb1c70cb10>}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for (var i  = 0; i < (this.config['n_layers']); i++) {\n",
    "#     this['conv'+ (i+1)] = tf.layers.conv2d({\n",
    "#         filters: this.config['n_feature_maps'],\n",
    "#         // inputShape: this.config['n_feature_maps'],\n",
    "#         kernelSize: this.config['conv_size'],\n",
    "#         padding: \"same\",\n",
    "#         dilation: 1,\n",
    "#         useBias: false,\n",
    "#         kernelInitializer: tf.initializers.zeros(),\n",
    "#         biasInitializer: tf.initializers.zeros(),\n",
    "#     })\n",
    "# }\n",
    "\n",
    "# (\"conv{}\".format(i + 1), conv\n",
    "\n",
    "for i in range(config['n_layers']):\n",
    "    conv = Conv2D(\n",
    "        filters=config['n_feature_maps'],\n",
    "        kernel_size=config['conv_size'],\n",
    "        strides=config['conv_stride'],\n",
    "        padding='same',\n",
    "        use_bias=False,\n",
    "        activation='relu',\n",
    "        kernel_initializer=keras.initializers.zeros(),\n",
    "        bias_initializer=keras.initializers.zeros(),\n",
    "        name = \"conv{}\".format(i + 1)\n",
    "    )\n",
    "    layers.update({\"conv{}\".format(i + 1) : conv})\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn0': <keras.layers.normalization.BatchNormalization at 0xb1c70c590>,\n",
       " 'bn1': <keras.layers.normalization.BatchNormalization at 0xb1c70c390>,\n",
       " 'bn2': <keras.layers.normalization.BatchNormalization at 0xb1c70c4d0>,\n",
       " 'bn3': <keras.layers.normalization.BatchNormalization at 0xb1c70cb50>,\n",
       " 'bn4': <keras.layers.normalization.BatchNormalization at 0xb1c72f0d0>,\n",
       " 'bn5': <keras.layers.normalization.BatchNormalization at 0xb1c72f210>,\n",
       " 'bn6': <keras.layers.normalization.BatchNormalization at 0xb1c72f350>,\n",
       " 'conv0': <keras.layers.convolutional.Conv2D at 0xb1c724090>,\n",
       " 'conv1': <keras.layers.convolutional.Conv2D at 0xb1c724a10>,\n",
       " 'conv2': <keras.layers.convolutional.Conv2D at 0xb1c724ad0>,\n",
       " 'conv3': <keras.layers.convolutional.Conv2D at 0xb1c724bd0>,\n",
       " 'conv4': <keras.layers.convolutional.Conv2D at 0xb1c724cd0>,\n",
       " 'conv5': <keras.layers.convolutional.Conv2D at 0xb1c724dd0>,\n",
       " 'conv6': <keras.layers.convolutional.Conv2D at 0xb1c724ed0>,\n",
       " 'pool': <keras.layers.pooling.AveragePooling2D at 0xb1c70cb10>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for (var i  = 0; i < (this.config['n_layers']); i++) {\n",
    "#     this['bn'+ (i+1)] = tf.layers.batchNormalization({\n",
    "#         epsilon: 0.00001,\n",
    "#         momentum: 0.1,\n",
    "#         gammaInitializer: tf.initializers.ones(),\n",
    "#         betaInitializer: tf.initializers.zeros(),\n",
    "#     })\n",
    "# }\n",
    "\n",
    "for i in range(config['n_layers'] + 1):\n",
    "    bn = BatchNormalization(\n",
    "        momentum=0.1, \n",
    "        epsilon=0.00001, \n",
    "        gamma_initializer=keras.initializers.ones(), \n",
    "        beta_initializer=keras.initializers.zeros(),\n",
    "        name=\"bn{}\".format(i)\n",
    "    )\n",
    "    layers.update({\"bn{}\".format(i) : bn})\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bn0': <keras.layers.normalization.BatchNormalization at 0xb1c70c590>,\n",
       " 'bn1': <keras.layers.normalization.BatchNormalization at 0xb1c70c390>,\n",
       " 'bn2': <keras.layers.normalization.BatchNormalization at 0xb1c70c4d0>,\n",
       " 'bn3': <keras.layers.normalization.BatchNormalization at 0xb1c70cb50>,\n",
       " 'bn4': <keras.layers.normalization.BatchNormalization at 0xb1c72f0d0>,\n",
       " 'bn5': <keras.layers.normalization.BatchNormalization at 0xb1c72f210>,\n",
       " 'bn6': <keras.layers.normalization.BatchNormalization at 0xb1c72f350>,\n",
       " 'conv0': <keras.layers.convolutional.Conv2D at 0xb1c724090>,\n",
       " 'conv1': <keras.layers.convolutional.Conv2D at 0xb1c724a10>,\n",
       " 'conv2': <keras.layers.convolutional.Conv2D at 0xb1c724ad0>,\n",
       " 'conv3': <keras.layers.convolutional.Conv2D at 0xb1c724bd0>,\n",
       " 'conv4': <keras.layers.convolutional.Conv2D at 0xb1c724cd0>,\n",
       " 'conv5': <keras.layers.convolutional.Conv2D at 0xb1c724dd0>,\n",
       " 'conv6': <keras.layers.convolutional.Conv2D at 0xb1c724ed0>,\n",
       " 'output': <keras.layers.core.Dense at 0x103d72d90>,\n",
       " 'pool': <keras.layers.pooling.AveragePooling2D at 0xb1c70cb10>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this.output = tf.layers.dense({\n",
    "#     units: this.config['n_labels'],\n",
    "#     activation: 'linear',\n",
    "#     biasInitializer : tf.initializers.zeros()\n",
    "# });\n",
    "\n",
    "layers['output'] = Dense(\n",
    "    config['n_labels'],\n",
    "    activation='linear', #None\n",
    "    use_bias=True,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    kernel_regularizer=None,\n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None,\n",
    "    kernel_constraint=None,\n",
    "    bias_constraint=None,\n",
    "    name=\"output\"\n",
    ")\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': <keras.layers.merge.Add at 0xb1c724310>,\n",
       " 'bn0': <keras.layers.normalization.BatchNormalization at 0xb1c70c590>,\n",
       " 'bn1': <keras.layers.normalization.BatchNormalization at 0xb1c70c390>,\n",
       " 'bn2': <keras.layers.normalization.BatchNormalization at 0xb1c70c4d0>,\n",
       " 'bn3': <keras.layers.normalization.BatchNormalization at 0xb1c70cb50>,\n",
       " 'bn4': <keras.layers.normalization.BatchNormalization at 0xb1c72f0d0>,\n",
       " 'bn5': <keras.layers.normalization.BatchNormalization at 0xb1c72f210>,\n",
       " 'bn6': <keras.layers.normalization.BatchNormalization at 0xb1c72f350>,\n",
       " 'conv0': <keras.layers.convolutional.Conv2D at 0xb1c724090>,\n",
       " 'conv1': <keras.layers.convolutional.Conv2D at 0xb1c724a10>,\n",
       " 'conv2': <keras.layers.convolutional.Conv2D at 0xb1c724ad0>,\n",
       " 'conv3': <keras.layers.convolutional.Conv2D at 0xb1c724bd0>,\n",
       " 'conv4': <keras.layers.convolutional.Conv2D at 0xb1c724cd0>,\n",
       " 'conv5': <keras.layers.convolutional.Conv2D at 0xb1c724dd0>,\n",
       " 'conv6': <keras.layers.convolutional.Conv2D at 0xb1c724ed0>,\n",
       " 'output': <keras.layers.core.Dense at 0x103d72d90>,\n",
       " 'pool': <keras.layers.pooling.AveragePooling2D at 0xb1c70cb10>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this.add = tf.layers.add();\n",
    "layers['add'] = Add();\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': <keras.layers.merge.Add at 0xb1c724310>,\n",
       " 'bn0': <keras.layers.normalization.BatchNormalization at 0xb1c70c590>,\n",
       " 'bn1': <keras.layers.normalization.BatchNormalization at 0xb1c70c390>,\n",
       " 'bn2': <keras.layers.normalization.BatchNormalization at 0xb1c70c4d0>,\n",
       " 'bn3': <keras.layers.normalization.BatchNormalization at 0xb1c70cb50>,\n",
       " 'bn4': <keras.layers.normalization.BatchNormalization at 0xb1c72f0d0>,\n",
       " 'bn5': <keras.layers.normalization.BatchNormalization at 0xb1c72f210>,\n",
       " 'bn6': <keras.layers.normalization.BatchNormalization at 0xb1c72f350>,\n",
       " 'conv0': <keras.layers.convolutional.Conv2D at 0xb1c724090>,\n",
       " 'conv1': <keras.layers.convolutional.Conv2D at 0xb1c724a10>,\n",
       " 'conv2': <keras.layers.convolutional.Conv2D at 0xb1c724ad0>,\n",
       " 'conv3': <keras.layers.convolutional.Conv2D at 0xb1c724bd0>,\n",
       " 'conv4': <keras.layers.convolutional.Conv2D at 0xb1c724cd0>,\n",
       " 'conv5': <keras.layers.convolutional.Conv2D at 0xb1c724dd0>,\n",
       " 'conv6': <keras.layers.convolutional.Conv2D at 0xb1c724ed0>,\n",
       " 'globalAvgPool': <keras.layers.pooling.GlobalAveragePooling2D at 0xb1c724650>,\n",
       " 'output': <keras.layers.core.Dense at 0x103d72d90>,\n",
       " 'pool': <keras.layers.pooling.AveragePooling2D at 0xb1c70cb10>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this.globalAvgPool = tf.layers.globalAveragePooling2d({});\n",
    "layers['globalAvgPool'] = GlobalAveragePooling2D();\n",
    "\n",
    "layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 100, 40, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 100, 40, 19)  171         input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool (AveragePooling2D)         (None, 25, 14, 19)   0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 25, 14, 19)   3249        pool[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 25, 14, 19)   76          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 25, 14, 19)   3249        bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 25, 14, 19)   0           conv2[0][0]                      \n",
      "                                                                 pool[0][0]                       \n",
      "                                                                 conv4[0][0]                      \n",
      "                                                                 add_1[0][0]                      \n",
      "                                                                 conv6[0][0]                      \n",
      "                                                                 add_1[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn2 (BatchNormalization)        (None, 25, 14, 19)   76          add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 25, 14, 19)   3249        bn2[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bn3 (BatchNormalization)        (None, 25, 14, 19)   76          conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Conv2D)                  (None, 25, 14, 19)   3249        bn3[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bn4 (BatchNormalization)        (None, 25, 14, 19)   76          add_1[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5 (Conv2D)                  (None, 25, 14, 19)   3249        bn4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bn5 (BatchNormalization)        (None, 25, 14, 19)   76          conv5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv6 (Conv2D)                  (None, 25, 14, 19)   3249        bn5[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "bn6 (BatchNormalization)        (None, 25, 14, 19)   76          add_1[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 19)           0           bn6[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 12)           240         global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 20,361\n",
      "Trainable params: 20,133\n",
      "Non-trainable params: 228\n",
      "__________________________________________________________________________________________________\n",
      "input { Input shape: (None, 100, 40, 1). Output shape: (None, 100, 40, 1) }\n",
      "conv0 { Input shape: (None, 100, 40, 1). Output shape: (None, 100, 40, 19) }\n",
      "pool { Input shape: (None, 100, 40, 19). Output shape: (None, 25, 14, 19) }\n",
      "conv1 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "bn1 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "conv2 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "add_1 { Input shape: [(None, 25, 14, 19), (None, 25, 14, 19)]. Output shape: (None, 25, 14, 19) }\n",
      "bn2 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "conv3 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "bn3 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "conv4 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "bn4 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "conv5 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "bn5 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "conv6 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "bn6 { Input shape: (None, 25, 14, 19). Output shape: (None, 25, 14, 19) }\n",
      "global_average_pooling2d_1 { Input shape: (None, 25, 14, 19). Output shape: (None, 19) }\n",
      "output { Input shape: (None, 19). Output shape: (None, 12) }\n"
     ]
    }
   ],
   "source": [
    "# tf.input({shape: this.config['input_shape']});\n",
    "input = Input(shape=config['input_shape'], name='input')\n",
    "x = input;\n",
    "\n",
    "# x = layers['bn0'](x)\n",
    "\n",
    "# x = x.unsqueeze(1)\n",
    "for i in range(config['n_layers'] + 1):\n",
    "#     y = F.relu(getattr(self, \"conv{}\".format(i))(x))\n",
    "    y = layers[\"conv{}\".format(i)](x)\n",
    "    if i == 0:\n",
    "#         if hasattr(self, \"pool\"):\n",
    "        if 'pool' in layers:\n",
    "#             y = self.pool(y)\n",
    "            y = layers['pool'](y)\n",
    "        old_x = y\n",
    "        \n",
    "    if i > 0 and i % 2 == 0:\n",
    "#         x = y + old_x\n",
    "        x = layers['add']([y, old_x])\n",
    "        old_x = x\n",
    "    else:\n",
    "        x = y\n",
    "        \n",
    "    if i > 0:\n",
    "#         x = getattr(self, \"bn{}\".format(i))(x)\n",
    "        x = layers[\"bn{}\".format(i)](x)\n",
    "    \n",
    "# x = x.view(x.size(0), x.size(1), -1) # shape: (batch, feats, o3)\n",
    "# x = torch.mean(x, 2)\n",
    "x = layers['globalAvgPool'](x)\n",
    "\n",
    "# return self.output(x)\n",
    "output = layers['output'](x)\n",
    "\n",
    "model = Model(inputs=input, outputs=output)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer.name + \" { Input shape: \"+str(layer.input_shape)+\". Output shape: \"+str(layer.output_shape) + \" }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  const optimizer = tf.train.momentum({\n",
    "#     learningRate: 0.1,\n",
    "#     momentum: 0.9,\n",
    "#     useNesterov: true\n",
    "# });\n",
    "# this.model.compile({\n",
    "#     optimizer: optimizer,\n",
    "#     loss: 'categoricalCrossentropy',\n",
    "#     metrics: ['accuracy'],\n",
    "# });\n",
    "\n",
    "# optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-5, momentum=0.9, nesterov=True)\n",
    "optimizer = keras.optimizers.SGD(\n",
    "    lr=0.00001, \n",
    "    decay=1e-5, \n",
    "    momentum=0.9, \n",
    "    nesterov=True\n",
    ")\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy', \n",
    "    optimizer=optimizer, \n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 100, 40, 1)\n",
      "(10, 12)\n"
     ]
    }
   ],
   "source": [
    "sample_batch_size = 10;\n",
    "\n",
    "sample_data = test_data.reshape(config['input_shape'])\n",
    "\n",
    "sample_label = np.zeros(config['n_labels']);\n",
    "sample_label[0] = 1\n",
    "\n",
    "# sample_label = np.zeros(config['n_labels']) + 0.01;\n",
    "# sample_label[0] = 1 - (0.01 * (config['n_labels'] - 1))\n",
    "\n",
    "batch_x = np.stack([sample_data] * sample_batch_size, axis = 0);\n",
    "batch_y = np.tile(sample_label,(sample_batch_size, 1))\n",
    "\n",
    "assert not np.any(np.isnan(batch_x))\n",
    "assert not np.any(np.isnan(batch_y))\n",
    "\n",
    "print batch_x.shape\n",
    "print batch_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        \n",
    "        self.fig = plt.figure()\n",
    "        \n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        \n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"val_loss\")\n",
    "        plt.legend()\n",
    "        plt.show();\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 1s 84ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: nan - acc: 1.0000\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 7ms/step - loss: nan - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb1cc2c510>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    batch_x, \n",
    "    batch_y, \n",
    "    epochs=10, \n",
    "    batch_size=sample_batch_size\n",
    ")\n",
    "\n",
    "# model.fit(\n",
    "#     batch_x, \n",
    "#     batch_y, \n",
    "#     epochs=10, \n",
    "#     batch_size=sample_batch_size, \n",
    "#     callbacks=[plot_losses],\n",
    "#     verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
